
import { GoogleGenerativeAI, SchemaType } from "@google/generative-ai";
import fs from 'fs';
import path from 'path';
import os from 'os';
// @ts-ignore
import { AssemblyWord } from "./assemblyBackend";
import { AlignedSegment } from "../types";

// Default Key (Fallback)
const DEFAULT_KEY = "AIzaSyC0QCO0_h3jb6l2rDV738Rv8hAvf6_5atk";

function getApiKey(): string {
  try {
    const configPath = path.join(os.homedir(), '.clicksync', 'config.json');
    if (fs.existsSync(configPath)) {
      const data = JSON.parse(fs.readFileSync(configPath, 'utf8'));
      if (data.geminiKey && data.geminiKey.trim().length > 10) {
        return data.geminiKey.trim();
      }
    }
  } catch (e) {
    console.error("Failed to load Gemini API key from config:", e);
  }
  return DEFAULT_KEY;
}

const genAI = new GoogleGenerativeAI(getApiKey());

export type { AlignedSegment }; // Re-export if needed, or consumers should import from types

// Re-introducing the Alignment logic, tailored for AssemblyAI's word format
export const alignScriptWithAssembly = async (
  scriptText: string,
  transcriptWords: AssemblyWord[]
): Promise<AlignedSegment[]> => {

  const model = genAI.getGenerativeModel({
    model: "gemini-3-pro-preview", // User requested to keep this model
    generationConfig: {
      responseMimeType: "application/json",
      responseSchema: {
        type: SchemaType.OBJECT,
        properties: {
          segments: {
            type: SchemaType.ARRAY,
            items: {
              type: SchemaType.OBJECT,
              properties: {
                title: { type: SchemaType.STRING },
                start_time: { type: SchemaType.NUMBER },
                end_time: { type: SchemaType.NUMBER }
              },
              required: ["title", "start_time", "end_time"]
            }
          }
        }
      }
    }
  });

  // Optimize token usage: AssemblyAI words have {text, start, end}. 
  // We can simplify this for the prompt if it's too huge, but Flash handles 1M tokens easily.
  // Passing the raw JSON array is fine for < 1 hour audio.

  const prompt = `
    You are an expert Video Editor and Aligner.
    
    OBJECTIVE:
    Align the provided SCRIPT with the detailed TRANSCRIPT (word-by-word timestamps) to identify the exact audio cut points for each news segment.
    
    INPUTS:
    1. SCRIPT: Contains identifying headers like [ON SCREEN: Title]. The text following matches the audio.
    2. TRANSCRIPT: A JSON list of words generated by AssemblyAI. "start" and "end" are in MILLISECONDS.
    
    INSTRUCTIONS:
    1. For each "[ON SCREEN: ...]" block in the script:
    2. Find the corresponding spoken text in the TRANSCRIPT.
    3. "start_time": The 'start' timestamp of the VERY FIRST word of that section.
    4. "end_time": The 'end' timestamp of the VERY LAST word of that section.
    5. IMPORTANT: Output 'start_time' and 'end_time' in SECONDS (convert ms to s by dividing by 1000).
    
    OUTPUT:
    Return valid JSON with a "segments" array.
    
    SCRIPT:
    ${scriptText}
    
    TRANSCRIPT JSON:
    ${JSON.stringify(transcriptWords)}
  `;

  try {
    const result = await model.generateContent(prompt);
    const response = await result.response;
    const resultText = response.text();

    if (!resultText) throw new Error("No response from Gemini");

    const parsed = JSON.parse(resultText);
    return parsed.segments;

  } catch (error) {
    console.error("Gemini Alignment Error:", error);
    throw error;
  }
};