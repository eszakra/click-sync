
import { GoogleGenerativeAI, SchemaType } from "@google/generative-ai";
import { GEMINI_API_KEY } from "../config";
// @ts-ignore
import { AssemblyWord } from "./assemblyBackend";

const genAI = new GoogleGenerativeAI(GEMINI_API_KEY);

export interface AlignedSegment {
  title: string;
  text?: string; // Added text field
  start_time: number;
  end_time: number;
}

// Re-introducing the Alignment logic, tailored for AssemblyAI's word format
export const alignScriptWithAssembly = async (
  scriptText: string,
  transcriptWords: AssemblyWord[]
): Promise<AlignedSegment[]> => {

  const model = genAI.getGenerativeModel({
    model: "gemini-1.5-flash-001",
    generationConfig: {
      responseMimeType: "application/json",
      responseSchema: {
        type: SchemaType.OBJECT,
        properties: {
          segments: {
            type: SchemaType.ARRAY,
            items: {
              type: SchemaType.OBJECT,
              properties: {
                title: { type: SchemaType.STRING },
                start_time: { type: SchemaType.NUMBER },
                end_time: { type: SchemaType.NUMBER }
              },
              required: ["title", "start_time", "end_time"]
            }
          }
        }
      }
    }
  });

  // Optimize token usage: AssemblyAI words have {text, start, end}. 
  // We can simplify this for the prompt if it's too huge, but Flash handles 1M tokens easily.
  // Passing the raw JSON array is fine for < 1 hour audio.

  const prompt = `
    You are an expert Video Editor and Aligner.
    
    OBJECTIVE:
    Align the provided SCRIPT with the detailed TRANSCRIPT (word-by-word timestamps) to identify the exact audio cut points for each news segment.
    
    INPUTS:
    1. SCRIPT: Contains identifying headers like [ON SCREEN: Title]. The text following matches the audio.
    2. TRANSCRIPT: A JSON list of words generated by AssemblyAI. "start" and "end" are in MILLISECONDS.
    
    INSTRUCTIONS:
    1. For each "[ON SCREEN: ...]" block in the script:
    2. Find the corresponding spoken text in the TRANSCRIPT.
    3. "start_time": The 'start' timestamp of the VERY FIRST word of that section.
    4. "end_time": The 'end' timestamp of the VERY LAST word of that section.
    5. IMPORTANT: Output 'start_time' and 'end_time' in SECONDS (convert ms to s by dividing by 1000).
    
    OUTPUT:
    Return valid JSON with a "segments" array.
    
    SCRIPT:
    ${scriptText}
    
    TRANSCRIPT JSON:
    ${JSON.stringify(transcriptWords)}
  `;

  try {
    const result = await model.generateContent(prompt);
    const response = await result.response;
    const resultText = response.text();

    if (!resultText) throw new Error("No response from Gemini");

    const parsed = JSON.parse(resultText);
    return parsed.segments;

  } catch (error) {
    console.error("Gemini Alignment Error:", error);
    throw error;
  }
};